[DEV]
BASE_PATH = xai_components

[SERVER]
IP_ADD = http://127.0.0.1
PORT = 5000

[REMOTE_EXECUTION]
# Xircuits remote execution configs using subprocess module (eg. for Spark submit etc.)
# Each run types will be shown on the toolbar dropdown.
# Separate each run type in a newline.
# Uncomment 'TEST' to add a new run type
RUN_TYPES = SPARK
        ;     TEST 

[RUN_TYPES]
# The types will be shown on each run types.
# Separate each run types and insert every run configurations in a newline.
SPARK = LOCAL
        CLUSTER
# Uncomment below to add new configs in the TEST's run type
; TEST = EG
;        EG2

[CONFIGURATION]
# Separate each config for each run types
# Make sure each config name is the same as the above. The name inside the bracket.
# Note: Create a unique name for each config types
# Note: Make sure every criteria is FILLED

[LOCAL]
name =  LOCAL
command = $SPARK_HOME/bin/spark-submit
msg = Running Spark Submit using local mode 
url = http://localhost:8088/

[CLUSTER]
name =  CLUSTER
command = $SPARK_HOME/bin/spark-submit \
        --py-files env_spark.zip \
        --archives env_spark.zip \
        --master yarn \
        --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH='/usr/local/cuda-11.2/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH' \
        --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON='/usr/local/bin/python3.9' \
        --conf spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON='/usr/local/bin/python3.9' \
        --num-executors=8 --executor-cores=1 --executor-memory=10G --driver-memory=10G \
        --name cluster_mode \
        --deploy-mode cluster \
        --conf spark.rpc.message.maxSize=1024 \
        --conf spark.driver.maxResultSize=10G 
msg = Running Spark Submit using YARN cluster mode 
url = http://localhost:8088/

[EG]
name =  EG
command = echo
msg = This config example will echo the python script name. 
url = http://localhost:8088/

[EG2]
name =  EG2
command = printf
msg = The 2nd config example will use printf to print the python script name.
url = http://localhost:8088/